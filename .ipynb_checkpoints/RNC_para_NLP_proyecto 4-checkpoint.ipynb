{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJ6zhycx-LJa"
   },
   "source": [
    "# Fase 1: Importar las dependencias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T00:55:07.638674Z",
     "start_time": "2020-11-10T00:55:05.463747Z"
    },
    "id": "NON9giQ1_eZy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T00:55:12.752774Z",
     "start_time": "2020-11-10T00:55:07.640675Z"
    },
    "id": "Un7jTbQNedR6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T00:55:17.496129Z",
     "start_time": "2020-11-10T00:55:12.754775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T00:55:19.515702Z",
     "start_time": "2020-11-10T00:55:17.499131Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\romil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\romil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud  # esto es para la nube de palabras\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk  # es una popular librería de Python que se utiliza para NLP.\n",
    "\n",
    "# Esto sirve para configurar NLTK. La primera vez puede tardar un poco\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Importamos el lemmatizar de NLTK, y creamos el objeto\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Importamos esta libreria que nos permite reemplzar caracteres\n",
    "\n",
    "\n",
    "from textblob import TextBlob #análisis de sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T00:55:21.735655Z",
     "start_time": "2020-11-10T00:55:19.517705Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_json('datos\\dataset_es_dev.json', lines=True)\n",
    "dataset2 = pd.read_json('datos\\dataset_es_test.json', lines=True)\n",
    "dataset3 = pd.read_json('datos\\dataset_es_train.json', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WN8EilQG-cwa"
   },
   "source": [
    "# Fase 2: Pre Procesado de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T00:55:21.767659Z",
     "start_time": "2020-11-10T00:55:21.737657Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "DAwqYIO259aZ",
    "outputId": "b479b79e-54a1-43b0-bcb1-a476f5fa50ba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_title</th>\n",
       "      <th>language</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>es_0491108</td>\n",
       "      <td>product_es_0296024</td>\n",
       "      <td>reviewer_es_0999081</td>\n",
       "      <td>1</td>\n",
       "      <td>Nada bueno se me fue ka pantalla en menos de 8...</td>\n",
       "      <td>television Nevir</td>\n",
       "      <td>es</td>\n",
       "      <td>electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>es_0869872</td>\n",
       "      <td>product_es_0922286</td>\n",
       "      <td>reviewer_es_0216771</td>\n",
       "      <td>1</td>\n",
       "      <td>Horrible, nos tuvimos que comprar otro porque ...</td>\n",
       "      <td>Dinero tirado a la basura con esta compra</td>\n",
       "      <td>es</td>\n",
       "      <td>electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>es_0811721</td>\n",
       "      <td>product_es_0474543</td>\n",
       "      <td>reviewer_es_0929213</td>\n",
       "      <td>1</td>\n",
       "      <td>Te obligan a comprar dos unidades y te llega s...</td>\n",
       "      <td>solo llega una unidad cuando te obligan a comp...</td>\n",
       "      <td>es</td>\n",
       "      <td>drugstore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>es_0359921</td>\n",
       "      <td>product_es_0656090</td>\n",
       "      <td>reviewer_es_0224702</td>\n",
       "      <td>1</td>\n",
       "      <td>No entro en descalificar al vendedor, solo pue...</td>\n",
       "      <td>PRODUCTO NO RECIBIDO.</td>\n",
       "      <td>es</td>\n",
       "      <td>wireless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>es_0068940</td>\n",
       "      <td>product_es_0662544</td>\n",
       "      <td>reviewer_es_0224827</td>\n",
       "      <td>1</td>\n",
       "      <td>Llega tarde y co la talla equivocada</td>\n",
       "      <td>Devuelto</td>\n",
       "      <td>es</td>\n",
       "      <td>shoes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_id          product_id          reviewer_id  stars  \\\n",
       "0  es_0491108  product_es_0296024  reviewer_es_0999081      1   \n",
       "1  es_0869872  product_es_0922286  reviewer_es_0216771      1   \n",
       "2  es_0811721  product_es_0474543  reviewer_es_0929213      1   \n",
       "3  es_0359921  product_es_0656090  reviewer_es_0224702      1   \n",
       "4  es_0068940  product_es_0662544  reviewer_es_0224827      1   \n",
       "\n",
       "                                         review_body  \\\n",
       "0  Nada bueno se me fue ka pantalla en menos de 8...   \n",
       "1  Horrible, nos tuvimos que comprar otro porque ...   \n",
       "2  Te obligan a comprar dos unidades y te llega s...   \n",
       "3  No entro en descalificar al vendedor, solo pue...   \n",
       "4               Llega tarde y co la talla equivocada   \n",
       "\n",
       "                                        review_title language product_category  \n",
       "0                                   television Nevir       es      electronics  \n",
       "1          Dinero tirado a la basura con esta compra       es      electronics  \n",
       "2  solo llega una unidad cuando te obligan a comp...       es        drugstore  \n",
       "3                              PRODUCTO NO RECIBIDO.       es         wireless  \n",
       "4                                           Devuelto       es            shoes  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset3.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5Md2zOM-SPH"
   },
   "source": [
    "El conjunto de datos de testing tiene 3 etiquetas diferentes (una negativa, una positiva y una neutra), mientras que el conjunto de datos de entrenamiento tiene solo dos, por lo que no usaremos el archivo de testing y dividiremos el archivo de entrenamiento más tarde nosotros mismos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T00:55:21.783659Z",
     "start_time": "2020-11-10T00:55:21.769659Z"
    },
    "id": "N-6BBPb3-OfY"
   },
   "outputs": [],
   "source": [
    "data = dataset3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6CsZKJx1-2Ep"
   },
   "source": [
    "## Pre Procesado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FLWayJ-5-7nN"
   },
   "source": [
    "### Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T00:55:21.815661Z",
     "start_time": "2020-11-10T00:55:21.786660Z"
    },
    "id": "Qa1v91RSkgz1"
   },
   "outputs": [],
   "source": [
    "data.drop([\"review_id\", \"product_id\", \"reviewer_id\", \"language\",\"product_category\"], # No te olvides de ejecutar data = train_data antes de nada!\n",
    "          axis=1,\n",
    "          inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T00:55:21.831663Z",
     "start_time": "2020-11-10T00:55:21.818664Z"
    }
   },
   "outputs": [],
   "source": [
    "#def clean_review(texto):\n",
    "#    texto = BeautifulSoup(texto, \"lxml\").get_text()\n",
    "    # Eliminamos la @ y su mención\n",
    "#    texto = re.sub(r\"@[A-Za-z0-9]+\", ' ', texto)\n",
    "    # Eliminamos los links de las URLs\n",
    "#    texto = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', texto)\n",
    "    # Nos quedamos solamente con los caracteres\n",
    "#    texto = re.sub(r\"[^a-zA-Z.!?']\", ' ', texto)\n",
    "    # Eliminamos espacios en blanco adicionales\n",
    "#    texto = re.sub(r\" +\", ' ', texto)\n",
    " #   return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T00:55:21.847664Z",
     "start_time": "2020-11-10T00:55:21.833665Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_review(texto):\n",
    "    texto = BeautifulSoup(texto, \"lxml\").get_text()\n",
    "    # Eliminamos \n",
    "    texto = re.sub(r\"[\\w]+\", ' ', texto)\n",
    "    # Eliminamos los links de las URLs\n",
    "    texto = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', texto)\n",
    "    # Nos quedamos solamente con los caracteres\n",
    "    texto = re.sub(r\"[^a-zA-Z.!?']\", ' ', texto)\n",
    "    # Eliminamos espacios en blanco adicionales\n",
    "    texto = re.sub(r\" +\", ' ', texto)\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T00:56:15.487162Z",
     "start_time": "2020-11-10T00:55:21.849665Z"
    },
    "id": "vq-mIZNdAUjE"
   },
   "outputs": [],
   "source": [
    "data_clean = [clean_review(texto) for texto in data.review_body]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T00:56:15.503165Z",
     "start_time": "2020-11-10T00:56:15.489165Z"
    },
    "id": "TqtCJZkhAb9C"
   },
   "outputs": [],
   "source": [
    "#data_labels = data.stars.values\n",
    "#data_labels[data_labels == 5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T00:56:15.535167Z",
     "start_time": "2020-11-10T00:56:15.505167Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NHrc3O6HlGjB",
    "outputId": "0814941c-e36a-477d-bfa9-6228b7dd31f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " ' ',\n",
       " ' !!',\n",
       " ' .... . . . . ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' . . . . . . .',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' . . . .',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' ! . . ..',\n",
       " ' .. ',\n",
       " ' .',\n",
       " ' . ! .',\n",
       " ' ... ... ... . ... ... ... . . ... .... ... ... . .',\n",
       " ' . . . .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' !!!.',\n",
       " ' ',\n",
       " ' !',\n",
       " ' . .',\n",
       " ' ... . . . . .',\n",
       " ' . ....',\n",
       " ' ? ',\n",
       " ' . .',\n",
       " ' . ',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' . .',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' . . .',\n",
       " ' . . ',\n",
       " ' . . . ',\n",
       " ' ... ... ',\n",
       " ' . .',\n",
       " ' . ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' . . . ',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' . . ',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' . . ',\n",
       " ' . ',\n",
       " ' .',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' .',\n",
       " ' . ',\n",
       " ' . . .',\n",
       " ' .',\n",
       " ' .',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' . . . ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . . . .',\n",
       " ' . . . .',\n",
       " ' ',\n",
       " ' !.... !!!',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' . . . . . .',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' ',\n",
       " ' .',\n",
       " ' ',\n",
       " ' .',\n",
       " ' . ',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' . .',\n",
       " ' . ',\n",
       " ' . . ',\n",
       " ' ..... ....',\n",
       " ' . . . . . .',\n",
       " ' .',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' . .',\n",
       " ' . .',\n",
       " ' . ... ! . .',\n",
       " ' . ',\n",
       " ' !',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' .',\n",
       " ' ',\n",
       " ' . . . . . . . . ',\n",
       " ' . . .',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' .',\n",
       " ' . . . . . ... . . . .',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' .',\n",
       " ' . .',\n",
       " ' .',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' . . . .',\n",
       " ' . . .',\n",
       " ' . .',\n",
       " ' . ... . . .',\n",
       " ' ... .....',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' .',\n",
       " ' . . . . . . .',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' . ',\n",
       " ' ',\n",
       " ' . . . .',\n",
       " ' . . .',\n",
       " ' .',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' . . ',\n",
       " ' . . .... ... ..... .',\n",
       " ' . . .',\n",
       " ' . . . .',\n",
       " ' .. .',\n",
       " ' . . ',\n",
       " ' . . . . . . ...',\n",
       " ' . ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' . . .',\n",
       " ' . ',\n",
       " ' . . ',\n",
       " ' .',\n",
       " ' . .',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' . . . . .',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' . . ',\n",
       " ' .',\n",
       " ' . ',\n",
       " ' ..... ',\n",
       " ' .',\n",
       " ' . .',\n",
       " ' ... . ',\n",
       " ' ',\n",
       " ' . . ??? . .... ',\n",
       " ' . . . .',\n",
       " ' . . . . . . .',\n",
       " ' ',\n",
       " ' . . . ....',\n",
       " ' . . . .',\n",
       " ' . . ',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' !',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ..... .',\n",
       " ' .',\n",
       " ' . ',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' . ',\n",
       " ' . . ... . .',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' . .',\n",
       " ' . . ',\n",
       " ' ',\n",
       " ' .',\n",
       " ' . .',\n",
       " ' . . . ',\n",
       " ' . .',\n",
       " ' .... .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' ',\n",
       " ' .',\n",
       " ' . . . . . ',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' . . ',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' . . . . ..',\n",
       " ' . . .',\n",
       " ' . ',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' .',\n",
       " ' . .',\n",
       " ' .',\n",
       " ' . . . .',\n",
       " ' . .',\n",
       " ' . .',\n",
       " ' . .',\n",
       " ' . .... .',\n",
       " ' . .',\n",
       " ' . . .',\n",
       " ' .',\n",
       " ' .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ... ?',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' .',\n",
       " ' . ',\n",
       " ' .',\n",
       " ' . ... ! . . ! ! .',\n",
       " ' .',\n",
       " ' ',\n",
       " ' .. . . .',\n",
       " ' . . .',\n",
       " ' . !! !! !!',\n",
       " ' ',\n",
       " ' . . . .',\n",
       " ' . .',\n",
       " ' .',\n",
       " ' . .',\n",
       " ' !! !! ',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' !! ?',\n",
       " ' !! . ',\n",
       " ' ',\n",
       " ' . !!!!! !!!!!!',\n",
       " ' . .',\n",
       " ' .',\n",
       " ' . .',\n",
       " ' . ',\n",
       " ' . . .',\n",
       " ' . . ',\n",
       " ' ',\n",
       " ' !!! !! !!! !!! !!!!',\n",
       " ' . . ',\n",
       " ' . . .',\n",
       " ' . .',\n",
       " ' .',\n",
       " ' ',\n",
       " ' .. .. .. . ',\n",
       " ' . .',\n",
       " ' . .',\n",
       " ' . .',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' .',\n",
       " ' .... ',\n",
       " ' . ',\n",
       " ' ',\n",
       " ' . . . . .',\n",
       " ' . .',\n",
       " ' . . . ',\n",
       " ' .',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' . . .',\n",
       " ' .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . . . .',\n",
       " ' ',\n",
       " ' . . . . . . .',\n",
       " ' . ??',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' . . . ',\n",
       " ' . . . . ?',\n",
       " ' . . . . ? ? .',\n",
       " ' .',\n",
       " ' . . ',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' !! . !',\n",
       " ' . ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' . . . .',\n",
       " ' . . ',\n",
       " ' . ! .',\n",
       " ' ... ',\n",
       " ' .... ... .. .. .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' .. .',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' . ',\n",
       " ' !!! . !',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' . . . . .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . . . . . . . . .',\n",
       " ' . .... . .',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' . . .',\n",
       " ' . . .',\n",
       " ' . ',\n",
       " ' . . .',\n",
       " ' . ',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' . . ',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' . . . ',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' !',\n",
       " ' . . . .',\n",
       " ' . . . . ',\n",
       " ' ... ',\n",
       " ' . ',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . . . .',\n",
       " ' . . .',\n",
       " ' . . . . ..... .',\n",
       " ' .',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' .',\n",
       " ' ',\n",
       " ' !!! . .',\n",
       " ' . .',\n",
       " ' . . ',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' . ...',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . . !',\n",
       " ' ...',\n",
       " ' . . . . . . . .',\n",
       " ' .',\n",
       " ' ',\n",
       " ' ! ! ! .',\n",
       " ' .',\n",
       " ' ',\n",
       " ' .. ... ... ....',\n",
       " ' . . . .... ',\n",
       " ' .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' .',\n",
       " ' . .... .... .',\n",
       " ' . .',\n",
       " ' . ',\n",
       " ' ',\n",
       " ' .. .. .',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' . . ',\n",
       " ' . !!',\n",
       " ' . .',\n",
       " ' ! !',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' ... ... ',\n",
       " ' . ',\n",
       " ' . ',\n",
       " ' .',\n",
       " ' .. .',\n",
       " ' . .',\n",
       " ' .',\n",
       " ' . . . . .',\n",
       " ' ',\n",
       " ' . . . .',\n",
       " ' . .',\n",
       " ' . ... ... ',\n",
       " ' ...',\n",
       " ' . . . !! . . .',\n",
       " ' ! ... !',\n",
       " ' . . ',\n",
       " ' ',\n",
       " ' . ...',\n",
       " ' ',\n",
       " ' ',\n",
       " ' .',\n",
       " ' . .',\n",
       " ' ... ... .. ! ',\n",
       " ' . .',\n",
       " ' . . ...',\n",
       " ' ',\n",
       " ' .... . .',\n",
       " ' ',\n",
       " ' .',\n",
       " ' . . . . . . .',\n",
       " ' .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' . . ',\n",
       " ' .',\n",
       " ' ',\n",
       " ' ... ..',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' . . ',\n",
       " ' .',\n",
       " ' ... ... ',\n",
       " ' ! . ....',\n",
       " ' .',\n",
       " ' . ',\n",
       " ' . .',\n",
       " ' . . !',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' .',\n",
       " ' ',\n",
       " ' . . . ',\n",
       " ' ',\n",
       " ' .',\n",
       " ' ',\n",
       " ' .',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' .... ... ... ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . !!!!!!!!',\n",
       " ' ',\n",
       " ' . . . . .',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' ',\n",
       " ' . . ',\n",
       " ' . .',\n",
       " ' ...',\n",
       " ' .',\n",
       " ' ?',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . . . . ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . . . ',\n",
       " ' .',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' . . . . .',\n",
       " ' .',\n",
       " ' . .',\n",
       " ' . ...',\n",
       " ' . . !',\n",
       " ' .',\n",
       " ' . . . .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' . . . . . . ?',\n",
       " ' ... . ...',\n",
       " ' . . .',\n",
       " ' .',\n",
       " ' ',\n",
       " ' .',\n",
       " ' . ',\n",
       " ' . .',\n",
       " ' . ',\n",
       " ' . .',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' ...',\n",
       " ' . ... .',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' . .',\n",
       " ' . . . .',\n",
       " ' ',\n",
       " ' .... ',\n",
       " ' ...',\n",
       " ' . .',\n",
       " ' . . . . . .',\n",
       " ' .. .... ',\n",
       " ' ',\n",
       " ' .',\n",
       " ' . . ',\n",
       " ' ',\n",
       " ' . . . .',\n",
       " ' . . .',\n",
       " ' . .',\n",
       " ' . . !',\n",
       " ' . .. .. ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . ... . . .',\n",
       " ' . . .',\n",
       " ' .',\n",
       " ' . . ',\n",
       " ' .',\n",
       " ' . ',\n",
       " ' .',\n",
       " ' . ',\n",
       " ' ',\n",
       " ' . . . . .',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' . ',\n",
       " ' . .',\n",
       " ' ! . .',\n",
       " ' . . . . . . . .',\n",
       " ' . ... ',\n",
       " ' . . . . . . . . . . . . .',\n",
       " ' . ... .... .',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' . . . . . . .',\n",
       " ' .',\n",
       " ' ! . !!!',\n",
       " ' ',\n",
       " ' . . ',\n",
       " ' .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . . ?',\n",
       " ' !!! . ??? ... ...',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' . . . .',\n",
       " ' .',\n",
       " ' .',\n",
       " ' . ',\n",
       " ' . ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' .',\n",
       " ' ! !',\n",
       " ' . . . ',\n",
       " ' . ',\n",
       " ' ! ? . . .',\n",
       " ' . . ',\n",
       " ' .',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' . .',\n",
       " ' . .',\n",
       " ' . . . . . .',\n",
       " ' . !!',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' .',\n",
       " ' ',\n",
       " ' . ... ',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' .... ... .',\n",
       " ' .',\n",
       " ' . !',\n",
       " ' ',\n",
       " ' .',\n",
       " ' . ! . . ',\n",
       " ' . . ... ',\n",
       " ' .',\n",
       " ' . . . .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . . . . ',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' . . . .',\n",
       " ' . . .',\n",
       " ' . . . .',\n",
       " ' !!! ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' .. ',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' . . . . . .',\n",
       " ' ',\n",
       " ' .... . . . ',\n",
       " ' .',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' ?',\n",
       " ' ',\n",
       " ' .',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' . !',\n",
       " ' . . . !',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . . . .',\n",
       " ' . . . ',\n",
       " ' . !!!',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' . ... .',\n",
       " ' . .',\n",
       " ' . . . . .',\n",
       " ' ',\n",
       " ' . ! ',\n",
       " ' . . ...',\n",
       " ' . . . ',\n",
       " ' ... .',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' .',\n",
       " ' . . . . .',\n",
       " ' ',\n",
       " ' .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' .',\n",
       " ' ',\n",
       " ' .. ... ..',\n",
       " ' . . ',\n",
       " ' .',\n",
       " ' ! . . . !!! !',\n",
       " ' ',\n",
       " ' . . . .',\n",
       " ' .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ..',\n",
       " ' ',\n",
       " ' . . ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ! .',\n",
       " ' ',\n",
       " ' .',\n",
       " ' . . . . .',\n",
       " ' ! . .',\n",
       " ' ',\n",
       " ' .... ',\n",
       " ' .',\n",
       " ' . . .',\n",
       " ' . . . ',\n",
       " ' .... ... ',\n",
       " ' ????',\n",
       " ' ! ... ... ... .... ... ! ... ... !!! !!! ... ... ',\n",
       " ' . .',\n",
       " ' . .',\n",
       " ' . . .',\n",
       " ' . ... . ? ? .',\n",
       " ' !!!!',\n",
       " ' !! . . . ',\n",
       " ' . . .',\n",
       " ' . .',\n",
       " ' .',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' . .',\n",
       " ' ... ... .',\n",
       " ' .',\n",
       " ' . . . .',\n",
       " ' ',\n",
       " ' . . . .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' . ',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' . ???????????????????',\n",
       " ' .. . .',\n",
       " ' ...',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' . ... ',\n",
       " ' ? .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' . . . .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . . . . .',\n",
       " ' .... ... .... ... ... .... ... ... ... .... ... ..... ',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' . . . .',\n",
       " ' ',\n",
       " ' . . . !',\n",
       " ' !!!!',\n",
       " ' ',\n",
       " ' . . . .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . . . ',\n",
       " ' .',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' .',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' ...',\n",
       " ' ...',\n",
       " ' . .',\n",
       " ' .',\n",
       " ' . ',\n",
       " ' . .',\n",
       " ' . .',\n",
       " ' ...',\n",
       " ' .',\n",
       " ' !',\n",
       " ' . . . ',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ... . ...',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' . .',\n",
       " ' . .',\n",
       " ' . . .',\n",
       " ' .... ...',\n",
       " ' ....',\n",
       " ' . . ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' .',\n",
       " ' ',\n",
       " ' !!!',\n",
       " ' . ',\n",
       " ' .',\n",
       " ' ',\n",
       " ' .... ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' . . ',\n",
       " ' . ',\n",
       " ' . ',\n",
       " ' ? .',\n",
       " ' . . ',\n",
       " ' ... ...',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' . . .',\n",
       " ' .... .... ',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' . . . . . . . .',\n",
       " ' . .',\n",
       " ' ...',\n",
       " ' ... ... . .',\n",
       " ' . ',\n",
       " ' .',\n",
       " ' . . .',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' . .',\n",
       " ' .',\n",
       " ' . . ',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' .',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' .',\n",
       " ' .',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' . . . . ',\n",
       " ' .... ...',\n",
       " ' . ... .',\n",
       " ' . . .',\n",
       " ' . . ... . .',\n",
       " ' ',\n",
       " ' .',\n",
       " ' . . .',\n",
       " ' . ',\n",
       " ' .',\n",
       " ' . . . . . . .',\n",
       " ' !!!! ',\n",
       " ' ',\n",
       " ' .',\n",
       " ' . ',\n",
       " ' ... ...',\n",
       " ' ? ',\n",
       " ' ',\n",
       " ' ..... ',\n",
       " ' . . ',\n",
       " ' . . ',\n",
       " ' !!!! .. .....',\n",
       " ' .. ',\n",
       " ' . !!',\n",
       " ' .',\n",
       " ' . . ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' .',\n",
       " ' . . . . .',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' . ?',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . . . ',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' . .',\n",
       " ' . .',\n",
       " ' . . .',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ! . ',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' .',\n",
       " ' . .',\n",
       " ' .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . ',\n",
       " ' .',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' . ',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' . . . . .',\n",
       " ' . .',\n",
       " ' ..',\n",
       " ' . . . .',\n",
       " ' . .',\n",
       " ' .',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' .',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' .',\n",
       " ' ',\n",
       " ' !! . . ..',\n",
       " ' ... ...',\n",
       " ' . .',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' . .',\n",
       " ' ',\n",
       " ' . . .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' .',\n",
       " ' . . . . . .',\n",
       " ' .',\n",
       " ' ',\n",
       " ' ',\n",
       " ' . . . ... ? ',\n",
       " ' . . ',\n",
       " ' ... ...',\n",
       " ' . .',\n",
       " ' .',\n",
       " ' . . . .',\n",
       " ' .',\n",
       " ' ... .',\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTKZ5fUh_Kxz"
   },
   "source": [
    "### Tokenización\n",
    "separar palabras del texto en entidades llamadas tokens, con las que trabajaremos luego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T00:56:33.945393Z",
     "start_time": "2020-11-10T00:56:15.537168Z"
    },
    "id": "IvmIKnAnAJRY"
   },
   "outputs": [],
   "source": [
    "tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    data_clean, target_vocab_size=2**16 #tamaño de mi corpus, las palabras que aparecen poco se eliminan\n",
    ")\n",
    "\n",
    "data_inputs = [tokenizer.encode(sentence) for sentence in data_clean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ysb2uib8n6b3"
   },
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T00:56:34.787460Z",
     "start_time": "2020-11-10T00:56:33.947394Z"
    },
    "id": "M9qttbt7BMwg"
   },
   "outputs": [],
   "source": [
    "#Vectorización de las palabras\n",
    "MAX_LEN = max([len(sentence) for sentence in data_inputs])\n",
    "data_inputs = tf.keras.preprocessing.sequence.pad_sequences(data_inputs,\n",
    "                                                            value=0,\n",
    "                                                            padding=\"post\",\n",
    "                                                            maxlen=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T00:56:35.008507Z",
     "start_time": "2020-11-10T00:56:34.789461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4034,    0,    0, ...,    0,    0,    0],\n",
       "       [4034,    0,    0, ...,    0,    0,    0],\n",
       "       [  32,    0,    0, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   2,    0,    0, ...,    0,    0,    0],\n",
       "       [4034,    0,    0, ...,    0,    0,    0],\n",
       "       [  26,    0,    0, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#impresión de mi matriz\n",
    "data_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4Ac7EXNNblp"
   },
   "source": [
    "### Dividimos en los conjuntos de entrenamiento y de testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T00:56:35.071518Z",
     "start_time": "2020-11-10T00:56:35.010509Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "X = data_inputs\n",
    "y = dataset3['stars'].values\n",
    "#pasar las estrellas de 0 a 4\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "y=le.transform(y)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,random_state=101)\n",
    "train_inputs, test_inputs, train_labels, test_labels = train_test_split(X, y,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T00:56:35.086918Z",
     "start_time": "2020-11-10T00:56:35.073520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 4, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWu6hLDG_UJZ"
   },
   "source": [
    "# Fase 3: Construción del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definición de red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T00:56:35.102240Z",
     "start_time": "2020-11-10T00:56:35.088916Z"
    },
    "id": "fD3nbD_M94Gt"
   },
   "outputs": [],
   "source": [
    "class DCNN(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 emb_dim=128, #dimensión de embedding\n",
    "                 nb_filters=50, #cantidad de filtros\n",
    "                 FFN_units=512, #cantidad de neuronas que queremos para redes neuronales densas\n",
    "                 nb_classes=2, #en primer instancia voy a definir como 2 clases pero despues voy a cambiarlo\n",
    "                 dropout_rate=0.1, #% de neurona que quiero apagar. Nos sirve para regularización y evitar el overfitting\n",
    "                 training=False,\n",
    "                 name=\"dcnn\"):\n",
    "        super(DCNN, self).__init__(name=name)\n",
    "        \n",
    "        self.embedding = layers.Embedding(vocab_size,    #embedding va organizando las palabras que tengo en mi corpus\n",
    "                                          emb_dim)\n",
    "        self.bigram = layers.Conv1D(filters=nb_filters,\n",
    "                                    kernel_size=2,\n",
    "                                    padding=\"valid\",\n",
    "                                    activation=\"relu\")\n",
    "        self.trigram = layers.Conv1D(filters=nb_filters,\n",
    "                                     kernel_size=3,\n",
    "                                     padding=\"valid\",\n",
    "                                     activation=\"relu\")\n",
    "        self.fourgram = layers.Conv1D(filters=nb_filters,\n",
    "                                      kernel_size=4,\n",
    "                                      padding=\"valid\",\n",
    "                                      activation=\"relu\")\n",
    "        self.pool = layers.GlobalMaxPool1D() # No tenemos variable de entrenamiento\n",
    "                                             # así que podemos usar la misma capa \n",
    "                                             # para cada paso de pooling\n",
    "        self.dense_1 = layers.Dense(units=FFN_units, activation=\"relu\") #capa de neuronas densas\n",
    "        self.dropout = layers.Dropout(rate=dropout_rate) #capa para regularización \n",
    "        \n",
    "        ####### Capa de salida ###################\n",
    "        if nb_classes == 2:\n",
    "            self.last_dense = layers.Dense(units=1,\n",
    "                                           activation=\"sigmoid\") #en el caso de que sea de dos clases\n",
    "        else:\n",
    "            self.last_dense = layers.Dense(units=nb_classes,\n",
    "                                           activation=\"softmax\") #en caso de que sean mas de dos clases\n",
    "      ##################################\n",
    "    def call(self, inputs, training):  #armando mi red neuronal 3capas de convolución \n",
    "        x = self.embedding(inputs)\n",
    "        x_1 = self.bigram(x)\n",
    "        x_1 = self.pool(x_1)\n",
    "        x_2 = self.trigram(x)\n",
    "        x_2 = self.pool(x_2)\n",
    "        x_3 = self.fourgram(x)\n",
    "        x_3 = self.pool(x_3)\n",
    "        \n",
    "        #concatenando los resultados en un vector y lo introduzco en mi red neuronal densa\n",
    "        merged = tf.concat([x_1, x_2, x_3], axis=-1) # (batch_size, 3 * nb_filters)\n",
    "        merged = self.dense_1(merged)\n",
    "        merged = self.dropout(merged, training)\n",
    "        output = self.last_dense(merged)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92XbAZ9E1AMS"
   },
   "source": [
    "# Paso 4: Aplicación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8cfYwHME-m0"
   },
   "source": [
    "## Configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T00:56:35.132526Z",
     "start_time": "2020-11-10T00:56:35.103239Z"
    },
    "id": "YXwGD-pqFG4n"
   },
   "outputs": [],
   "source": [
    "#definición de parametros para cambiar los de que puse por default\n",
    "\n",
    "VOCAB_SIZE = tokenizer.vocab_size # 65540\n",
    "\n",
    "EMB_DIM = 200\n",
    "NB_FILTERS = 100\n",
    "FFN_UNITS = 256\n",
    "NB_CLASSES = len(set(train_labels)) #cantidad nros de estrellas diferentes -- cantidad diferente en mi etiqueta \n",
    "\n",
    "DROPOUT_RATE = 0.8 #regularización \n",
    "                \n",
    "BATCH_SIZE =60 #32 Reducimos los pesos\n",
    "NB_EPOCHS = 5 #epocas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nddzr1kA7UHC"
   },
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T00:56:35.335259Z",
     "start_time": "2020-11-10T00:56:35.134527Z"
    },
    "id": "1ETcf5Wl4Q-7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#instanciamos la clase DCNN para actualizar los parametros\n",
    "Dcnn = DCNN(vocab_size=VOCAB_SIZE,\n",
    "            emb_dim=EMB_DIM,\n",
    "            nb_filters=NB_FILTERS,\n",
    "            FFN_units=FFN_UNITS,\n",
    "            nb_classes=NB_CLASSES,\n",
    "            dropout_rate=DROPOUT_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T00:56:35.351258Z",
     "start_time": "2020-11-10T00:56:35.337258Z"
    },
    "id": "XCuNhMNk4n_u"
   },
   "outputs": [],
   "source": [
    "#Definimos función de pérdida, optimizador y métrica\n",
    "if NB_CLASSES == 2:\n",
    "    Dcnn.compile(loss=\"binary_crossentropy\",\n",
    "                 optimizer=\"adam\",\n",
    "                 metrics=[\"accuracy\"])\n",
    "else:\n",
    "    Dcnn.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                 optimizer=\"adam\",\n",
    "                 metrics=[\"sparse_categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T00:56:35.367259Z",
     "start_time": "2020-11-10T00:56:35.355259Z"
    },
    "id": "A1X7h6Bx5Upc"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = r\"C:\\proyecto\" #ruta donde se guardaria la red entrenada.. deberia estar en tu local!\n",
    "\n",
    "ckpt = tf.train.Checkpoint(Dcnn=Dcnn)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print(\"Último checkpoint restaurado!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T00:56:35.383261Z",
     "start_time": "2020-11-10T00:56:35.369261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  92,    0,    0, ...,    0,    0,    0],\n",
       "       [   1,    0,    0, ...,    0,    0,    0],\n",
       "       [4034,    0,    0, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   4,    0,    0, ...,    0,    0,    0],\n",
       "       [  12,    0,    0, ...,    0,    0,    0],\n",
       "       [   2,    0,    0, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualización de matriz entrenada\n",
    "train_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-10T00:55:05.521Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "6eL9EMsa6Igy",
    "outputId": "86ed9057-b489-47cd-d813-f534ce757c8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method DCNN.call of <__main__.DCNN object at 0x0000027A73C8AA88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method DCNN.call of <__main__.DCNN object at 0x0000027A73C8AA88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method DCNN.call of <__main__.DCNN object at 0x0000027A73C8AA88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method DCNN.call of <__main__.DCNN object at 0x0000027A73C8AA88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method DCNN.call of <__main__.DCNN object at 0x0000027A73C8AA88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method DCNN.call of <__main__.DCNN object at 0x0000027A73C8AA88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 47760/140000 [=========>....................] - ETA: 35s - loss: 1.6094 - sparse_categorical_accuracy: 0.2063"
     ]
    }
   ],
   "source": [
    "#Entrenamiento de red neuronal\n",
    "Dcnn.fit(train_inputs,\n",
    "         train_labels,\n",
    "         batch_size=BATCH_SIZE,\n",
    "         epochs=NB_EPOCHS)\n",
    "#ckpt_manager.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16Gn6JhJKXDK"
   },
   "source": [
    "## Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-10T00:55:05.524Z"
    },
    "id": "Jt2dRZWhKHbT"
   },
   "outputs": [],
   "source": [
    "#Evaluación de mi entrenamiento\n",
    "results = Dcnn.evaluate(test_inputs, test_labels, batch_size=BATCH_SIZE)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-10T00:55:05.526Z"
    },
    "id": "te0SJTWe2EVb"
   },
   "outputs": [],
   "source": [
    "#ejemplo\n",
    "import codecs\n",
    "Dcnn(np.array([tokenizer.encode(\"Este dispositivo perfecto porque cumple\")]), training=False).numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-10T00:55:05.528Z"
    },
    "id": "s-bAxtCk2Y-m"
   },
   "outputs": [],
   "source": [
    "tokenizer.encode(\"You are so funny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-10T00:55:05.530Z"
    }
   },
   "outputs": [],
   "source": [
    "#tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-10T00:55:05.532Z"
    }
   },
   "outputs": [],
   "source": [
    "#!conda update tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of RNC para NLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
